{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zoom-blur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "from PIL import Image\n",
    "from collections import defaultdict\n",
    "import google.generativeai as genai\n",
    "\n",
    "# Configure Gemini API\n",
    "API_KEY = \"<INSERT YOUR GEMINI API KEY HERE>\"\n",
    "genai.configure(api_key=API_KEY)\n",
    "model = genai.GenerativeModel(\"gemini-2.0-flash\")\n",
    "\n",
    "# Paths\n",
    "DATA_PATH = \"Noisy-Denoised_QuestionPairs[new].csv\"\n",
    "CHECKPOINT_PATH = \"checkpoint_Zoom-Blur_NoisyNoisy.json\"\n",
    "\n",
    "# Load dataset\n",
    "data = pd.read_csv(DATA_PATH)\n",
    "\n",
    "# Load previous progress if exists\n",
    "if os.path.exists(CHECKPOINT_PATH):\n",
    "    with open(CHECKPOINT_PATH, \"r\") as f:\n",
    "        checkpoint_data = json.load(f)\n",
    "    \n",
    "    # Use .get() to prevent KeyError if the key does not exist\n",
    "    processed_questions = defaultdict(list, checkpoint_data.get(\"processed_questions\", {}))\n",
    "    noise_type_accuracy = defaultdict(lambda: {\"correct\": 0, \"total\": 0}, checkpoint_data.get(\"accuracy\", {}))\n",
    "    total_correct = checkpoint_data.get(\"total_correct\", 0)\n",
    "    total_predictions = checkpoint_data.get(\"total_predictions\", 0)\n",
    "else:\n",
    "    processed_questions = defaultdict(list)\n",
    "    noise_type_accuracy = defaultdict(lambda: {\"correct\": 0, \"total\": 0})\n",
    "    total_correct = 0\n",
    "    total_predictions = 0\n",
    "\n",
    "\n",
    "# Iterate over rows where category is \"count\"\n",
    "for index, row in data.iterrows():\n",
    "    if row[\"category\"] != \"count\":\n",
    "        continue  # Skip non-count categories\n",
    "\n",
    "    question_id = row[\"id\"]\n",
    "    noise_type = row[\"modified_question_function_name\"]\n",
    "\n",
    "    # Skip if this specific question with this noise type was already processed\n",
    "    if noise_type in processed_questions[question_id]:\n",
    "        continue\n",
    "\n",
    "    image_path = f\"Noisy DARE TEST/Zoom-Blur/{row['path']}\"\n",
    "    \n",
    "    try:\n",
    "        image = Image.open(image_path)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Image not found: {image_path}. Skipping...\")\n",
    "        continue\n",
    "\n",
    "    # Prepare prompt\n",
    "    question_type = row[\"category\"]\n",
    "    question = row[\"modified_question\"]\n",
    "    options = {key: row[key] for key in [\"A\", \"B\", \"C\", \"D\"]}\n",
    "    \n",
    "    prompt_text = (\n",
    "        f\"The following are multiple-choice questions about {question_type}. \"\n",
    "        \"You should directly answer the question by choosing the correct option given the image and the question. \"\n",
    "        \"Give only the letter indicating the correct answer e.g., 'A'.\\n\"\n",
    "        f\"Question: {question}\\n\"\n",
    "        \"Options:\\n\"\n",
    "        f\"A. {options['A']}\\n\"\n",
    "        f\"B. {options['B']}\\n\"\n",
    "        f\"C. {options['C']}\\n\"\n",
    "        f\"D. {options['D']}\\n\"\n",
    "        \"Answer:\"\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        # Send request to Gemini API\n",
    "        response = model.generate_content([prompt_text, image])\n",
    "        full_answer = response.text.strip()\n",
    "        predicted_answer = full_answer.split()[-1]  # Extract last word\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"API error: {e}. Saving checkpoint and exiting...\")\n",
    "        break  # Stop execution to prevent further API exhaustion\n",
    "\n",
    "    # Evaluate accuracy\n",
    "    if predicted_answer == row[\"answer\"][2]:  # Compare with actual answer\n",
    "        noise_type_accuracy[noise_type][\"correct\"] += 1\n",
    "        total_correct += 1\n",
    "    noise_type_accuracy[noise_type][\"total\"] += 1\n",
    "    total_predictions += 1\n",
    "\n",
    "    # Mark this (question_id, noise_type) pair as processed\n",
    "    processed_questions[question_id].append(noise_type)\n",
    "\n",
    "    # Save checkpoint every 50 iterations\n",
    "    if total_predictions % 50 == 0:\n",
    "        checkpoint_data = {\n",
    "            \"processed_questions\": dict(processed_questions),\n",
    "            \"accuracy\": dict(noise_type_accuracy),\n",
    "            \"total_correct\": total_correct,\n",
    "            \"total_predictions\": total_predictions,\n",
    "        }\n",
    "        with open(CHECKPOINT_PATH, \"w\") as f:\n",
    "            json.dump(checkpoint_data, f)\n",
    "        print(f\"Checkpoint saved at {CHECKPOINT_PATH}\")\n",
    "\n",
    "    # Print progress\n",
    "    print(f\"Question ID {row['id']} - Predicted: {predicted_answer} - Actual: {row['answer']} - Noise: {noise_type}\")\n",
    "    print(f\"Progress: {total_correct}/{total_predictions} and OVERALL accuracy percentage: {(total_correct / total_predictions) * 100}%\")\n",
    "    print(\"Noise Type Accuracy so far:\")\n",
    "    for n_type, counts in noise_type_accuracy.items():\n",
    "        print(f\"{n_type}: {counts['correct']}/{counts['total']} and {n_type} accuracy percentage: {(counts['correct'] / counts['total']) * 100}%\")\n",
    "    print(\"----------------------\")\n",
    "\n",
    "# Final checkpoint save\n",
    "checkpoint_data = {\n",
    "    \"processed_questions\": dict(processed_questions),\n",
    "    \"accuracy\": dict(noise_type_accuracy),\n",
    "    \"total_correct\": total_correct,\n",
    "    \"total_predictions\": total_predictions,\n",
    "}\n",
    "with open(CHECKPOINT_PATH, \"w\") as f:\n",
    "    json.dump(checkpoint_data, f)\n",
    "\n",
    "print(f\"Final checkpoint saved at {CHECKPOINT_PATH}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sks",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
