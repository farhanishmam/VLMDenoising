{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM\n",
    "from janus.models import MultiModalityCausalLM, VLChatProcessor\n",
    "from janus.utils.io import load_pil_images\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from PIL import Image\n",
    "\n",
    "# specify the path to the model\n",
    "model_path = \"deepseek-ai/Janus-Pro-7B\"\n",
    "vl_chat_processor: VLChatProcessor = VLChatProcessor.from_pretrained(model_path)\n",
    "tokenizer = vl_chat_processor.tokenizer\n",
    "\n",
    "vl_gpt: MultiModalityCausalLM = AutoModelForCausalLM.from_pretrained(\n",
    "    model_path, trust_remote_code=True\n",
    ")\n",
    "vl_gpt = vl_gpt.to(torch.bfloat16).cuda().eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "data = pd.read_csv(\"[without images]1_correct_validation.csv\")\n",
    "\n",
    "# Initialize counters for accuracy per noise type\n",
    "noise_type_accuracy = defaultdict(lambda: {\"correct\": 0, \"total\": 0})\n",
    "\n",
    "\n",
    "#Get the correct count\n",
    "correct_cnt = 0\n",
    "total_questions = 0   \n",
    "\n",
    "\n",
    "# Iterate over rows where category is \"count\"\n",
    "for index, row in data.iterrows():\n",
    "    if row[\"category\"] != \"count\":\n",
    "        continue  # Skip non-count categories\n",
    "\n",
    "    total_questions += 1\n",
    "    # Load the corresponding image\n",
    "    image_path = f\"1_correct_validation_images/{row['path']}\"\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        image = Image.open(image_path)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Image not found: {image_path}. Skipping...\")\n",
    "        continue\n",
    "\n",
    "    # Prepare the conversation\n",
    "    conversation = [\n",
    "        {\n",
    "            \"role\": \"User\",\n",
    "            \"content\": \"<image_placeholder>\\nThe following are multiple choice questions about count. You should directly answer the question by choosing the correct option given the image and the question. Give only the letter indicating the correct answer e.g. 'A'\\n\"\n",
    "            f\"Question: {row['question']}\\n\"\n",
    "            \"Options:\\n\"\n",
    "            f\"A. {row['A']}\\n\"\n",
    "            f\"B. {row['B']}\\n\"\n",
    "            f\"C. {row['C']}\\n\"\n",
    "            f\"D. {row['D']}\\n\"\n",
    "            \"Answer:\",\n",
    "            \"images\": [image_path],\n",
    "        },\n",
    "        {\"role\": \"Assistant\", \"content\": \"\"},\n",
    "    ]\n",
    "\n",
    "    # load images and prepare for inputs\n",
    "    pil_images = load_pil_images(conversation)\n",
    "    prepare_inputs = vl_chat_processor(\n",
    "        conversations=conversation, images=pil_images, force_batchify=True\n",
    "    ).to(vl_gpt.device)\n",
    "\n",
    "    # run image encoder to get the image embeddings\n",
    "    inputs_embeds = vl_gpt.prepare_inputs_embeds(**prepare_inputs)\n",
    "\n",
    "    # run the model to get the response\n",
    "    outputs = vl_gpt.language_model.generate(\n",
    "        inputs_embeds=inputs_embeds,\n",
    "        attention_mask=prepare_inputs.attention_mask,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "        bos_token_id=tokenizer.bos_token_id,\n",
    "        eos_token_id=tokenizer.eos_token_id,\n",
    "        max_new_tokens=512,\n",
    "        do_sample=False,\n",
    "        use_cache=True,\n",
    "    )\n",
    "\n",
    "    answer = tokenizer.decode(outputs[0].cpu().tolist(), skip_special_tokens=True)\n",
    "    predicted_answer = answer.split()[-1]  # Get the last word (e.g., \"A\", \"B\", \"C\", or \"D\")\n",
    "\n",
    "\n",
    "    # Compare with the actual answer and update counters\n",
    "    if predicted_answer == row[\"answer\"][2]:\n",
    "        correct_cnt += 1\n",
    "\n",
    "    # Print the prediction\n",
    "    print(f\"Question ID {row['id']} - Predicted Answer: {predicted_answer} - Actual Answer: {row['answer']}\")\n",
    "\n",
    "\n",
    "# Calculate Accuracy\n",
    "print(f\"Total Correct:  {correct_cnt}\")\n",
    "print(f\"Total Questions:  {total_questions}\")\n",
    "print(f\"Accuracy: {(correct_cnt/total_questions) * 100} % \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "data = pd.read_csv(\"[without images]1_correct_validation.csv\")\n",
    "\n",
    "# Initialize counters for accuracy per noise type\n",
    "noise_type_accuracy = defaultdict(lambda: {\"correct\": 0, \"total\": 0})\n",
    "\n",
    "\n",
    "#Get the correct count\n",
    "correct_cnt = 0\n",
    "total_questions = 0   \n",
    "\n",
    "\n",
    "# Iterate over rows where category is \"count\"\n",
    "for index, row in data.iterrows():\n",
    "    if row[\"category\"] != \"order\":\n",
    "        continue  # Skip non-count categories\n",
    "\n",
    "    total_questions += 1\n",
    "    # Load the corresponding image\n",
    "    image_path = f\"1_correct_validation_images/{row['path']}\"\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        image = Image.open(image_path)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Image not found: {image_path}. Skipping...\")\n",
    "        continue\n",
    "\n",
    "    # Prepare the conversation\n",
    "    conversation = [\n",
    "        {\n",
    "            \"role\": \"User\",\n",
    "            \"content\": \"<image_placeholder>\\nThe following are multiple choice questions about count. You should directly answer the question by choosing the correct option given the image and the question. Give only the letter indicating the correct answer e.g. 'A'\\n\"\n",
    "            f\"Question: {row['question']}\\n\"\n",
    "            \"Options:\\n\"\n",
    "            f\"A. {row['A']}\\n\"\n",
    "            f\"B. {row['B']}\\n\"\n",
    "            f\"C. {row['C']}\\n\"\n",
    "            f\"D. {row['D']}\\n\"\n",
    "            \"Answer:\",\n",
    "            \"images\": [image_path],\n",
    "        },\n",
    "        {\"role\": \"Assistant\", \"content\": \"\"},\n",
    "    ]\n",
    "\n",
    "    # load images and prepare for inputs\n",
    "    pil_images = load_pil_images(conversation)\n",
    "    prepare_inputs = vl_chat_processor(\n",
    "        conversations=conversation, images=pil_images, force_batchify=True\n",
    "    ).to(vl_gpt.device)\n",
    "\n",
    "    # run image encoder to get the image embeddings\n",
    "    inputs_embeds = vl_gpt.prepare_inputs_embeds(**prepare_inputs)\n",
    "\n",
    "    # run the model to get the response\n",
    "    outputs = vl_gpt.language_model.generate(\n",
    "        inputs_embeds=inputs_embeds,\n",
    "        attention_mask=prepare_inputs.attention_mask,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "        bos_token_id=tokenizer.bos_token_id,\n",
    "        eos_token_id=tokenizer.eos_token_id,\n",
    "        max_new_tokens=512,\n",
    "        do_sample=False,\n",
    "        use_cache=True,\n",
    "    )\n",
    "\n",
    "    answer = tokenizer.decode(outputs[0].cpu().tolist(), skip_special_tokens=True)\n",
    "    predicted_answer = answer.split()[-1]  # Get the last word (e.g., \"A\", \"B\", \"C\", or \"D\")\n",
    "\n",
    "\n",
    "    # Compare with the actual answer and update counters\n",
    "    if predicted_answer == row[\"answer\"][2]:\n",
    "        correct_cnt += 1\n",
    "\n",
    "    # Print the prediction\n",
    "    print(f\"Question ID {row['id']} - Predicted Answer: {predicted_answer} - Actual Answer: {row['answer']}\")\n",
    "\n",
    "\n",
    "# Calculate Accuracy\n",
    "print(f\"Total Correct:  {correct_cnt}\")\n",
    "print(f\"Total Questions:  {total_questions}\")\n",
    "print(f\"Accuracy: {(correct_cnt/total_questions) * 100} % \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "data = pd.read_csv(\"[without images]1_correct_validation.csv\")\n",
    "\n",
    "# Initialize counters for accuracy per noise type\n",
    "noise_type_accuracy = defaultdict(lambda: {\"correct\": 0, \"total\": 0})\n",
    "\n",
    "\n",
    "#Get the correct count\n",
    "correct_cnt = 0\n",
    "total_questions = 0   \n",
    "\n",
    "\n",
    "# Iterate over rows where category is \"count\"\n",
    "for index, row in data.iterrows():\n",
    "    if row[\"category\"] != \"trick\":\n",
    "        continue  # Skip non-count categories\n",
    "\n",
    "    total_questions += 1\n",
    "    # Load the corresponding image\n",
    "    image_path = f\"1_correct_validation_images/{row['path']}\"\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        image = Image.open(image_path)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Image not found: {image_path}. Skipping...\")\n",
    "        continue\n",
    "\n",
    "    # Prepare the conversation\n",
    "    conversation = [\n",
    "        {\n",
    "            \"role\": \"User\",\n",
    "            \"content\": \"<image_placeholder>\\nThe following are multiple choice questions about count. You should directly answer the question by choosing the correct option given the image and the question. Give only the letter indicating the correct answer e.g. 'A'\\n\"\n",
    "            f\"Question: {row['question']}\\n\"\n",
    "            \"Options:\\n\"\n",
    "            f\"A. {row['A']}\\n\"\n",
    "            f\"B. {row['B']}\\n\"\n",
    "            f\"C. {row['C']}\\n\"\n",
    "            f\"D. {row['D']}\\n\"\n",
    "            \"Answer:\",\n",
    "            \"images\": [image_path],\n",
    "        },\n",
    "        {\"role\": \"Assistant\", \"content\": \"\"},\n",
    "    ]\n",
    "\n",
    "    # load images and prepare for inputs\n",
    "    pil_images = load_pil_images(conversation)\n",
    "    prepare_inputs = vl_chat_processor(\n",
    "        conversations=conversation, images=pil_images, force_batchify=True\n",
    "    ).to(vl_gpt.device)\n",
    "\n",
    "    # run image encoder to get the image embeddings\n",
    "    inputs_embeds = vl_gpt.prepare_inputs_embeds(**prepare_inputs)\n",
    "\n",
    "    # run the model to get the response\n",
    "    outputs = vl_gpt.language_model.generate(\n",
    "        inputs_embeds=inputs_embeds,\n",
    "        attention_mask=prepare_inputs.attention_mask,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "        bos_token_id=tokenizer.bos_token_id,\n",
    "        eos_token_id=tokenizer.eos_token_id,\n",
    "        max_new_tokens=512,\n",
    "        do_sample=False,\n",
    "        use_cache=True,\n",
    "    )\n",
    "\n",
    "    answer = tokenizer.decode(outputs[0].cpu().tolist(), skip_special_tokens=True)\n",
    "    predicted_answer = answer.split()[-1]  # Get the last word (e.g., \"A\", \"B\", \"C\", or \"D\")\n",
    "\n",
    "\n",
    "    # Compare with the actual answer and update counters\n",
    "    if predicted_answer == row[\"answer\"][2]:\n",
    "        correct_cnt += 1\n",
    "\n",
    "    # Print the prediction\n",
    "    print(f\"Question ID {row['id']} - Predicted Answer: {predicted_answer} - Actual Answer: {row['answer']}\")\n",
    "\n",
    "\n",
    "# Calculate Accuracy\n",
    "print(f\"Total Correct:  {correct_cnt}\")\n",
    "print(f\"Total Questions:  {total_questions}\")\n",
    "print(f\"Accuracy: {(correct_cnt/total_questions) * 100} % \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "data = pd.read_csv(\"[without images]1_correct_validation.csv\")\n",
    "\n",
    "# Initialize counters for accuracy per noise type\n",
    "noise_type_accuracy = defaultdict(lambda: {\"correct\": 0, \"total\": 0})\n",
    "\n",
    "\n",
    "#Get the correct count\n",
    "correct_cnt = 0\n",
    "total_questions = 0   \n",
    "\n",
    "\n",
    "# Iterate over rows where category is \"count\"\n",
    "for index, row in data.iterrows():\n",
    "    if row[\"category\"] != \"vcr\":\n",
    "        continue  # Skip non-count categories\n",
    "\n",
    "    total_questions += 1\n",
    "    # Load the corresponding image\n",
    "    image_path = f\"1_correct_validation_images/{row['path']}\"\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        image = Image.open(image_path)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Image not found: {image_path}. Skipping...\")\n",
    "        continue\n",
    "\n",
    "    # Prepare the conversation\n",
    "    conversation = [\n",
    "        {\n",
    "            \"role\": \"User\",\n",
    "            \"content\": \"<image_placeholder>\\nThe following are multiple choice questions about count. You should directly answer the question by choosing the correct option given the image and the question. Give only the letter indicating the correct answer e.g. 'A'\\n\"\n",
    "            f\"Question: {row['question']}\\n\"\n",
    "            \"Options:\\n\"\n",
    "            f\"A. {row['A']}\\n\"\n",
    "            f\"B. {row['B']}\\n\"\n",
    "            f\"C. {row['C']}\\n\"\n",
    "            f\"D. {row['D']}\\n\"\n",
    "            \"Answer:\",\n",
    "            \"images\": [image_path],\n",
    "        },\n",
    "        {\"role\": \"Assistant\", \"content\": \"\"},\n",
    "    ]\n",
    "\n",
    "    # load images and prepare for inputs\n",
    "    pil_images = load_pil_images(conversation)\n",
    "    prepare_inputs = vl_chat_processor(\n",
    "        conversations=conversation, images=pil_images, force_batchify=True\n",
    "    ).to(vl_gpt.device)\n",
    "\n",
    "    # run image encoder to get the image embeddings\n",
    "    inputs_embeds = vl_gpt.prepare_inputs_embeds(**prepare_inputs)\n",
    "\n",
    "    # run the model to get the response\n",
    "    outputs = vl_gpt.language_model.generate(\n",
    "        inputs_embeds=inputs_embeds,\n",
    "        attention_mask=prepare_inputs.attention_mask,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "        bos_token_id=tokenizer.bos_token_id,\n",
    "        eos_token_id=tokenizer.eos_token_id,\n",
    "        max_new_tokens=512,\n",
    "        do_sample=False,\n",
    "        use_cache=True,\n",
    "    )\n",
    "\n",
    "    answer = tokenizer.decode(outputs[0].cpu().tolist(), skip_special_tokens=True)\n",
    "    predicted_answer = answer.split()[-1]  # Get the last word (e.g., \"A\", \"B\", \"C\", or \"D\")\n",
    "\n",
    "\n",
    "    # Compare with the actual answer and update counters\n",
    "    if predicted_answer == row[\"answer\"][2]:\n",
    "        correct_cnt += 1\n",
    "\n",
    "    # Print the prediction\n",
    "    print(f\"Question ID {row['id']} - Predicted Answer: {predicted_answer} - Actual Answer: {row['answer']}\")\n",
    "\n",
    "\n",
    "# Calculate Accuracy\n",
    "print(f\"Total Correct:  {correct_cnt}\")\n",
    "print(f\"Total Questions:  {total_questions}\")\n",
    "print(f\"Accuracy: {(correct_cnt/total_questions) * 100} % \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sks",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
