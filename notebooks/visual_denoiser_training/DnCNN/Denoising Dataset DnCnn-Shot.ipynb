{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "from glob import glob\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the base directory where noisy image folders are located\n",
    "base_dir = 'Data/Images/'\n",
    "\n",
    "\n",
    "# Iterate through each subfolder in the root directory\n",
    "for folder_name in os.listdir(base_dir):\n",
    "    folder_path = os.path.join(base_dir, folder_name)\n",
    "    \n",
    "    # Check if it's a directory\n",
    "    if os.path.isdir(folder_path):\n",
    "        # Count the number of files in the directory\n",
    "        file_count = len([f for f in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, f))])\n",
    "        print(f\"{folder_name}: {file_count} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import torchvision.models as models\n",
    "import torch.nn as n\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import time\n",
    "from PIL import Image\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_dir = 'filtered_images/'\n",
    "noisy_base_dir = 'Shot-noise/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenoisingDataset(Dataset):\n",
    "    def __init__(self, clean_dir, noisy_base_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            clean_dir (string): Directory with all the clean images.\n",
    "            noisy_base_dir (string): Directory with subfolders for each noise type, and inside each noise type, folders for severity levels.\n",
    "            transform (callable, optional): Optional transform to be applied on a sample (e.g., ToTensor, Normalize).\n",
    "        \"\"\"\n",
    "        self.clean_dir = clean_dir\n",
    "        self.noisy_base_dir = noisy_base_dir\n",
    "        self.transform = transform\n",
    "        self.clean_images = sorted(os.listdir(clean_dir))\n",
    "        # self.noise_types = sorted(os.listdir(noisy_base_dir))  # e.g., Brightness, Contrast\n",
    "        \n",
    "        self.noisy_images = []\n",
    "        # for noise_type in self.noise_types:\n",
    "        for severity_level in range(1, 6):  # Assuming L1 to L5\n",
    "            noisy_folder = os.path.join(noisy_base_dir, f'L{severity_level}')\n",
    "            print(noisy_folder)\n",
    "            noisy_images = sorted(os.listdir(noisy_folder))\n",
    "            print(noisy_images)\n",
    "            self.noisy_images.extend([(os.path.join(noisy_folder, img), os.path.join(clean_dir, img)) for img in noisy_images])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.noisy_images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        noisy_path, clean_path = self.noisy_images[idx]\n",
    "        noisy_image = Image.open(noisy_path).convert('RGB')\n",
    "        clean_image = Image.open(clean_path).convert('RGB')\n",
    "\n",
    "        if self.transform:\n",
    "            noisy_image = self.transform(noisy_image)\n",
    "            clean_image = self.transform(clean_image)\n",
    "\n",
    "        return noisy_image, clean_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the dataset\n",
    "dataset = DenoisingDataset(clean_dir=clean_dir, \n",
    "                           noisy_base_dir=noisy_base_dir,\n",
    "                           transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the correct noisy-clean pairs are returned\n",
    "def test_denoising_dataset(dataset, num_samples=3001):\n",
    "    for i in range(num_samples):\n",
    "        noisy_image_path, clean_image_path = dataset.noisy_images[i]  # Get the file paths of noisy and clean images\n",
    "        \n",
    "        # Extract file names from the paths\n",
    "        noisy_folder_name = \"/\".join(noisy_image_path.split('/')[-3:-1])  # Folder name of noisy image\n",
    "        noisy_image_name = noisy_image_path.split('/')[-1]  # File name of noisy image\n",
    "        \n",
    "        clean_folder_name = clean_image_path.split('/')[-2]  # Folder name of clean image\n",
    "        clean_image_name = clean_image_path.split('/')[-1]  # File name of clean image\n",
    "        \n",
    "        # Print folder and file names to confirm matching\n",
    "        print(f\"Clean Image: Folder = {clean_folder_name}, Image = {clean_image_name}\")\n",
    "        print(f\"Noisy Image: Folder = {noisy_folder_name}, Image = {noisy_image_name}\\n\")\n",
    "\n",
    "# Test the dataset to see 5 random noisy-clean image file pairs\n",
    "test_denoising_dataset(dataset, num_samples=3001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install deepinv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepinv.models import DnCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dncnn_model = DnCNN(in_channels=3, out_channels=3, depth=20, pretrained='download', device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the device to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dncnn_model = dncnn_model.to(device)\n",
    "dncnn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example input: batch of 32 images (with 1 channel, e.g., grayscale)\n",
    "example_input = torch.randn(32, 3, 224, 224).to(device)  # Shape: (batch_size, channels, height, width)\n",
    "# Forward pass through the model\n",
    "with torch.no_grad():  # Disable gradient calculation for inference\n",
    "    output = dncnn_model(example_input)  # Forward pass through the DnCNN model\n",
    "\n",
    "print(output.shape)  # Should print (32, 1, 224, 224) if using residual connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_size = len(dataset)\n",
    "total_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.70 * total_size)  # 70% for training\n",
    "val_size = int(0.15 * total_size)    # 15% for validation\n",
    "test_size = total_size - train_size - val_size  # Remaining 15% for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into train, validation, and test sets\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_dataset))\n",
    "print(len(test_dataset))\n",
    "print(len(val_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define batch size\n",
    "batch_size = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "    # Convert tensor to numpy array, and unnormalize if needed\n",
    "    img = img.numpy().transpose((1, 2, 0))  # Change from CxHxW to HxWxC\n",
    "    img = np.clip(img, 0, 1)  # Ensure values are in [0, 1]\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "\n",
    "# Get a batch of training images\n",
    "data_iter = iter(train_loader)\n",
    "noisy_images, clean_images = next(data_iter)\n",
    "\n",
    "# Plot some images\n",
    "num_images = 4  # Number of images to display\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "for i in range(num_images):\n",
    "    plt.subplot(2, num_images // 2, i + 1)\n",
    "    imshow(noisy_images[i])\n",
    "    plt.title('Noisy Image')\n",
    "    \n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "for i in range(num_images):\n",
    "    plt.subplot(2, num_images // 2, i + 1)\n",
    "    imshow(clean_images[i])\n",
    "    plt.title('Clean Image')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "import time\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(outputs, clean_images):\n",
    "    \"\"\"Calculate PSNR and SSIM between outputs and clean images.\"\"\"\n",
    "    batch_size = outputs.size(0)\n",
    "    # print(batch_size)\n",
    "    psnr_values = []\n",
    "    ssim_values = []\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        # Reshape images to (224, 224, 3) if they are flattened\n",
    "        output_image = outputs[i].cpu().detach().numpy().reshape(224, 224, 3)\n",
    "        clean_image = clean_images[i].cpu().detach().numpy().reshape(224, 224, 3)\n",
    "\n",
    "        # Calculate PSNR\n",
    "        psnr_values.append(psnr(clean_image, output_image, data_range=clean_image.max() - clean_image.min())) # stores psnr values for each image in the batch\n",
    "        \n",
    "        # Calculate SSIM\n",
    "        ssim_values.append(ssim(clean_image, output_image, data_range=clean_image.max() - clean_image.min(), multichannel=True, win_size=3)) # stores ssim values for each image in the batch\n",
    "\n",
    "    return np.mean(psnr_values), np.mean(ssim_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: iterate through the DataLoader\n",
    "for images, labels in train_loader:\n",
    "    print(f\"Batch size: {images.size(0)}, Clean image shape: {images.size()}, Noisy image shape: {labels.size()}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of epochs\n",
    "num_epochs = 50\n",
    "learning_rate = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss_history = []  # To store training loss for each epoch\n",
    "val_loss_history = []    # To store validation loss for each epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the training function\n",
    "def train_dncnn(model, train_loader, val_loader, num_epochs, learning_rate):\n",
    "    model.to(device)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    best_val_loss = float('inf')  # Initialize to infinity\n",
    "    best_epoch = 0  # To keep track of which epoch had the best model\n",
    "    early_stop_patience = 10\n",
    "    patience_counter = 0\n",
    "    \n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # --- TRAINING PHASE ---\n",
    "        model.train() # Set the model to training mode\n",
    "        total_loss = 0.0\n",
    "        \n",
    "        \n",
    "        for noisy_images, clean_images in train_loader:\n",
    "            noisy_images = noisy_images.to(device)\n",
    "            clean_images = clean_images.to(device)\n",
    "            \n",
    "            # Check shapes\n",
    "            # print(f'Noisy images shape: {noisy_images.shape}')  # Should be (B, 3, 224, 224) or (B, C, H, W)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(noisy_images)\n",
    "            loss = criterion(outputs, clean_images)\n",
    "            \n",
    "            # Backward pass and optimization\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item() * noisy_images.size(0)\n",
    "            \n",
    "        avg_train_loss = total_loss / len(train_loader)\n",
    "        train_loss_history.append(avg_train_loss)  # Store train loss\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval() # Set the model to evaluation mode\n",
    "        val_loss = 0.0\n",
    "        total_psnr = 0.0\n",
    "        total_ssim = 0.0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for noisy_images, clean_images in val_loader:\n",
    "                noisy_images = noisy_images.to(device)\n",
    "                clean_images = clean_images.to(device)\n",
    "\n",
    "                # Forward pass: Get model predictions\n",
    "                outputs = model(noisy_images)\n",
    "                loss = criterion(outputs, clean_images)\n",
    "                \n",
    "                # Accumulate the validation loss\n",
    "                val_loss += loss.item()*noisy_images.size(0)\n",
    "                \n",
    "                # print(f\"Outputs shape: {outputs.shape}, Clean images shape: {clean_images.shape}\")\n",
    "                psnr_value, ssim_value = calculate_metrics(outputs, clean_images)\n",
    "                total_psnr += psnr_value\n",
    "                total_ssim += ssim_value\n",
    "        \n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        val_loss_history.append(avg_val_loss)  # Store validation loss\n",
    "        \n",
    "        avg_psnr = total_psnr / len(val_loader)\n",
    "        avg_ssim = total_ssim / len(val_loader)\n",
    "        \n",
    "        # Check if this is the best validation loss so far\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            best_epoch = epoch + 1\n",
    "            patience_counter = 0  # Reset patience counter if validation improves\n",
    "            torch.save(model.state_dict(), 'Shot_DnCNN.pt')  # Save the model\n",
    "            print(f'Saved best model at epoch {best_epoch} with validation loss: {best_val_loss:.4f}')\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            \n",
    "        # Early stopping condition\n",
    "        if patience_counter >= early_stop_patience:\n",
    "            print(f'Early stopping at epoch {epoch+1} due to no improvement in validation loss for {early_stop_patience} consecutive epochs.')\n",
    "            break\n",
    "\n",
    "        # print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss / len(train_loader):.4f}')\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}, Average PSNR: {avg_psnr:.4f}, Average SSIM: {avg_ssim:.4f}')\n",
    "        print(f'Time taken: {time.time() - start_time:.2f} seconds\\n')\n",
    "    print(f\"Training complete. Best model saved at epoch {best_epoch} with validation loss: {best_val_loss:.4f}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_on_test(model, test_loader):\n",
    "    # Load the best model saved during training\n",
    "    model.load_state_dict(torch.load('Shot_DnCNN.pt'))\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    total_psnr = 0\n",
    "    total_ssim = 0\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for noisy_images, clean_images in test_loader:  # Use test_loader here\n",
    "            noisy_images = noisy_images.to(device)\n",
    "            clean_images = clean_images.to(device)\n",
    "\n",
    "            outputs = model(noisy_images)\n",
    "            loss = criterion(outputs, clean_images)\n",
    "            test_loss += loss.item()*noisy_images.size(0)\n",
    "            # print(test_loss)\n",
    "\n",
    "            psnr_value, ssim_value = calculate_metrics(outputs, clean_images)\n",
    "            total_psnr += psnr_value\n",
    "            total_ssim += ssim_value\n",
    "\n",
    "    avg_test_loss = test_loss / len(test_loader)\n",
    "    avg_psnr = total_psnr / len(test_loader)\n",
    "    avg_ssim = total_ssim / len(test_loader)\n",
    "\n",
    "    print(f'Test Loss: {avg_test_loss:.4f}, Average PSNR: {avg_psnr:.4f}, Average SSIM: {avg_ssim:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start training the model\n",
    "train_dncnn(dncnn_model, train_loader, val_loader, num_epochs, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Plot the Loss Curves ---\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(train_loss_history, label='Training Loss')\n",
    "plt.plot(val_loss_history, label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model_on_test(dncnn_model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the model to evaluation mode\n",
    "dncnn_model.load_state_dict(torch.load('Shot_DnCNN.pt'))\n",
    "dncnn_model.to(device)\n",
    "# Set the model to evaluation mode\n",
    "dncnn_model.eval()\n",
    "\n",
    "# Get a few images from the test set\n",
    "with torch.no_grad():\n",
    "    # Get a single batch from the test loader\n",
    "    noisy_images, clean_images = next(iter(test_loader))\n",
    "    \n",
    "    # Move to the appropriate device\n",
    "    noisy_images = noisy_images.to(device)\n",
    "    clean_images = clean_images.to(device)\n",
    "\n",
    "    # Pass the noisy images through the autoencoder\n",
    "    denoised_images = dncnn_model(noisy_images)\n",
    "\n",
    "# Convert to numpy for visualization\n",
    "noisy_images_np = noisy_images.cpu().numpy()\n",
    "clean_images_np = clean_images.cpu().numpy()\n",
    "denoised_images_np = denoised_images.cpu().numpy()\n",
    "\n",
    "# Function to visualize images\n",
    "def plot_images(noisy, clean, denoised, num_images=4):\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    for i in range(num_images):\n",
    "        # Noisy image\n",
    "        plt.subplot(3, num_images, i + 1)\n",
    "        plt.imshow(noisy[i].transpose(1, 2, 0))\n",
    "        plt.title(\"Noisy\")\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "        # Clean image\n",
    "        plt.subplot(3, num_images, i + 1 + num_images)\n",
    "        plt.imshow(clean[i].transpose(1, 2, 0))\n",
    "        plt.title(\"Clean\")\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "        # Denoised image\n",
    "        plt.subplot(3, num_images, i + 1 + 2 * num_images)\n",
    "        plt.imshow(denoised[i].transpose(1, 2, 0))\n",
    "        plt.title(\"Denoised\")\n",
    "        plt.axis(\"off\")\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "# Plot the images\n",
    "plot_images(noisy_images_np, clean_images_np, denoised_images_np, num_images=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = 'denoising_dataset/Shot-noise/L5/COCO_val2014_000000000074.jpg'\n",
    "noisy_image = Image.open(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transformations to convert the image to tensor\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # Converts the image to [0, 1] range and converts to tensor\n",
    "    transforms.Resize((224, 224)),  # Resizes the image if necessary\n",
    "])\n",
    "\n",
    "# Apply transformation and add batch dimension (batch size 1)\n",
    "noisy_image_tensor = transform(noisy_image).unsqueeze(0)  # Shape: [1, channels, height, width]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure the model is in evaluation mode\n",
    "dncnn_model.eval()\n",
    "\n",
    "# If using a GPU, move the image tensor to the GPU\n",
    "noisy_image_tensor = noisy_image_tensor.to('cuda')  # Use 'cpu' if no GPU is available\n",
    "\n",
    "# Perform inference without computing gradients\n",
    "with torch.no_grad():\n",
    "    denoised_image = dncnn_model(noisy_image_tensor)\n",
    "\n",
    "# The output denoised_image will be a tensor, shape: [1, channels, height, width]\n",
    "print(denoised_image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as T\n",
    "\n",
    "# Move the output back to CPU if using GPU\n",
    "denoised_image = denoised_image.cpu()\n",
    "noisy_image_tensor = noisy_image_tensor.cpu()\n",
    "\n",
    "# Remove batch dimensions for both images\n",
    "noisy_image = noisy_image_tensor.squeeze(0)  # Shape: [channels, height, width]\n",
    "denoised_image = denoised_image.squeeze(0)  # Shape: [channels, height, width]\n",
    "\n",
    "# Convert both tensors to PIL images\n",
    "noisy_image = T.ToPILImage()(noisy_image)\n",
    "denoised_image = T.ToPILImage()(denoised_image)\n",
    "\n",
    "# Plot both images side by side\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "# Display noisy image\n",
    "axs[0].imshow(noisy_image)\n",
    "axs[0].axis('off')\n",
    "axs[0].set_title('Noisy Image')\n",
    "\n",
    "# Display denoised image\n",
    "axs[1].imshow(denoised_image)\n",
    "axs[1].axis('off')\n",
    "axs[1].set_title('Denoised Image')\n",
    "\n",
    "# Show the figure\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = 'denoising_dataset/Shot-noise/L4/COCO_val2014_000000000074.jpg'\n",
    "noisy_image = Image.open(image_path)\n",
    "\n",
    "# Define transformations to convert the image to tensor\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # Converts the image to [0, 1] range and converts to tensor\n",
    "    transforms.Resize((224, 224)),  # Resizes the image if necessary\n",
    "])\n",
    "\n",
    "# Apply transformation and add batch dimension (batch size 1)\n",
    "noisy_image_tensor = transform(noisy_image).unsqueeze(0)  # Shape: [1, channels, height, width]\n",
    "\n",
    "# Make sure the model is in evaluation mode\n",
    "dncnn_model.eval()\n",
    "\n",
    "# If using a GPU, move the image tensor to the GPU\n",
    "noisy_image_tensor = noisy_image_tensor.to('cuda')  # Use 'cpu' if no GPU is available\n",
    "\n",
    "# Perform inference without computing gradients\n",
    "with torch.no_grad():\n",
    "    denoised_image = dncnn_model(noisy_image_tensor)\n",
    "\n",
    "# The output denoised_image will be a tensor, shape: [1, channels, height, width]\n",
    "print(denoised_image.shape)\n",
    "\n",
    "denoised_image = denoised_image.cpu()\n",
    "noisy_image_tensor = noisy_image_tensor.cpu()\n",
    "\n",
    "# Remove batch dimensions for both images\n",
    "noisy_image = noisy_image_tensor.squeeze(0)  # Shape: [channels, height, width]\n",
    "denoised_image = denoised_image.squeeze(0)  # Shape: [channels, height, width]\n",
    "\n",
    "# Convert both tensors to PIL images\n",
    "noisy_image = T.ToPILImage()(noisy_image)\n",
    "denoised_image = T.ToPILImage()(denoised_image)\n",
    "\n",
    "# Plot both images side by side\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "# Display noisy image\n",
    "axs[0].imshow(noisy_image)\n",
    "axs[0].axis('off')\n",
    "axs[0].set_title('Noisy Image')\n",
    "\n",
    "# Display denoised image\n",
    "axs[1].imshow(denoised_image)\n",
    "axs[1].axis('off')\n",
    "axs[1].set_title('Denoised Image')\n",
    "\n",
    "# Show the figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = 'denoising_dataset/Shot-noise/L3/COCO_val2014_000000000133.jpg'\n",
    "noisy_image = Image.open(image_path)\n",
    "\n",
    "# Define transformations to convert the image to tensor\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # Converts the image to [0, 1] range and converts to tensor\n",
    "    transforms.Resize((224, 224)),  # Resizes the image if necessary\n",
    "])\n",
    "\n",
    "# Apply transformation and add batch dimension (batch size 1)\n",
    "noisy_image_tensor = transform(noisy_image).unsqueeze(0)  # Shape: [1, channels, height, width]\n",
    "\n",
    "# Make sure the model is in evaluation mode\n",
    "dncnn_model.eval()\n",
    "\n",
    "# If using a GPU, move the image tensor to the GPU\n",
    "noisy_image_tensor = noisy_image_tensor.to('cuda')  # Use 'cpu' if no GPU is available\n",
    "\n",
    "# Perform inference without computing gradients\n",
    "with torch.no_grad():\n",
    "    denoised_image = dncnn_model(noisy_image_tensor)\n",
    "\n",
    "# The output denoised_image will be a tensor, shape: [1, channels, height, width]\n",
    "print(denoised_image.shape)\n",
    "\n",
    "denoised_image = denoised_image.cpu()\n",
    "noisy_image_tensor = noisy_image_tensor.cpu()\n",
    "\n",
    "# Remove batch dimensions for both images\n",
    "noisy_image = noisy_image_tensor.squeeze(0)  # Shape: [channels, height, width]\n",
    "denoised_image = denoised_image.squeeze(0)  # Shape: [channels, height, width]\n",
    "\n",
    "# Convert both tensors to PIL images\n",
    "noisy_image = T.ToPILImage()(noisy_image)\n",
    "denoised_image = T.ToPILImage()(denoised_image)\n",
    "\n",
    "# Plot both images side by side\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "# Display noisy image\n",
    "axs[0].imshow(noisy_image)\n",
    "axs[0].axis('off')\n",
    "axs[0].set_title('Noisy Image')\n",
    "\n",
    "# Display denoised image\n",
    "axs[1].imshow(denoised_image)\n",
    "axs[1].axis('off')\n",
    "axs[1].set_title('Denoised Image')\n",
    "\n",
    "# Show the figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sks",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
