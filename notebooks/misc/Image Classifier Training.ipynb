{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the base directory where noisy image folders are located\n",
    "base_dir = 'Data/Images/'\n",
    "\n",
    "\n",
    "# Iterate through each subfolder in the root directory\n",
    "for folder_name in os.listdir(base_dir):\n",
    "    folder_path = os.path.join(base_dir, folder_name)\n",
    "    \n",
    "    # Check if it's a directory\n",
    "    if os.path.isdir(folder_path):\n",
    "        # Count the number of files in the directory\n",
    "        file_count = len([f for f in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, f))])\n",
    "        print(f\"{folder_name}: {file_count} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input directory containing noise-type severity folders\n",
    "input_dir = 'Data/Images/'\n",
    "output_dir = 'dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the noise types and severity levels\n",
    "noise_types = [\n",
    "    \"Brightness\", \"Contrast\", \"Defocus-blur\", \"Elastic\", \"Fog\",\n",
    "    \"Frost\", \"Gaussian-noise\", \"Impulse-noise\", \"JPEG-compression\", \"Motion-Blur\",\n",
    "    \"Pixelate\", \"Rain\", \"Saturation\", \"Shot-noise\", \"Snow\", \"Spatter\",\n",
    "    \"Speckle-noise\", \"Zoom-Blur\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # the split ratio for train, validation, and test\n",
    "train_ratio = 0.7\n",
    "val_ratio = 0.15\n",
    "test_ratio = 0.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "\n",
    "# Define the path to your dataset directory\n",
    "dataset_dir = 'dataset/' \n",
    "\n",
    "# Define the splits (train, val, test)\n",
    "splits = ['train', 'val', 'test']\n",
    "\n",
    "# Function to count the number of images in each noise type folder\n",
    "def count_images_in_each_folder():\n",
    "    # Iterate over each split (train, val, test)\n",
    "    for split in splits:\n",
    "        print(f\"--- {split.upper()} ---\")\n",
    "        \n",
    "        # Get the list of noise type folders inside each split directory\n",
    "        noise_type_folders = os.listdir(os.path.join(dataset_dir, split))\n",
    "        \n",
    "        # Iterate over each noise type folder\n",
    "        for noise_type in noise_type_folders:\n",
    "            # Get the path to the folder\n",
    "            folder_path = os.path.join(dataset_dir, split, noise_type)\n",
    "            \n",
    "            # Count the number of images in the folder (recursively if there are subfolders)\n",
    "            images = glob(os.path.join(folder_path, \"**\", \"*.jpg\"), recursive=True)  # Assuming images are .jpg files\n",
    "            \n",
    "            # Print the number of images for the current noise type folder\n",
    "            print(f\"{noise_type}: {len(images)} images\")\n",
    "        print(\"\\n\")\n",
    "\n",
    "# Run the function to count and display the images in each folder\n",
    "count_images_in_each_folder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time\n",
    "from PIL import Image\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transformations\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize images to 224x224\n",
    "    transforms.RandomHorizontalFlip(),  # Data augmentation: random horizontal flip\n",
    "    transforms.ToTensor(),  # Convert image to PyTorch tensor\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize with ImageNet values\n",
    "])\n",
    "\n",
    "test_val_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Dataset class\n",
    "class NoiseClassificationDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            root_dir (string): Directory with all the images, split into subfolders by class.\n",
    "            transform (callable, optional): Optional transform to be applied on a sample.\n",
    "        \"\"\"\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.images = []\n",
    "        self.labels = []\n",
    "        self.noise_types = sorted(os.listdir(root_dir))  # Subfolders represent classes\n",
    "        \n",
    "        # Load images and labels\n",
    "        for noise_type_idx, noise_type in enumerate(self.noise_types):\n",
    "            noise_folder = os.path.join(root_dir, noise_type)\n",
    "            for img_name in os.listdir(noise_folder):\n",
    "                img_path = os.path.join(noise_folder, img_name)\n",
    "                self.images.append(img_path)\n",
    "                self.labels.append(noise_type_idx)  # Label is index of noise type\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "        image = Image.open(img_path).convert('RGB')  # Ensure it's an RGB image\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dataset directories\n",
    "train_dir = 'dataset/train/'\n",
    "val_dir = 'dataset/val/'\n",
    "test_dir = 'dataset/test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datasets\n",
    "train_dataset = NoiseClassificationDataset(root_dir=train_dir, transform=train_transforms)\n",
    "val_dataset = NoiseClassificationDataset(root_dir=val_dir, transform=test_val_transforms)\n",
    "test_dataset = NoiseClassificationDataset(root_dir=test_dir, transform=test_val_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define batch size\n",
    "batch_size = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print dataset sizes\n",
    "print(f\"Train dataset size: {len(train_dataset)} images\")\n",
    "print(f\"Validation dataset size: {len(val_dataset)} images\")\n",
    "print(f\"Test dataset size: {len(test_dataset)} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: iterate through the DataLoader\n",
    "for images, labels in train_loader:\n",
    "    print(f\"Batch size: {images.size(0)}, Image shape: {images.size()}, Labels shape: {labels.size()}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the device to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import ResNet50_Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a pre-trained ResNet model and modify the final layer for noise classification\n",
    "num_classes = 18  # Number of noise types\n",
    "resnet_model = models.resnet50(weights=ResNet50_Weights.DEFAULT)\n",
    "\n",
    "# Replace the final fully connected layer to match the number of classes (noise types)\n",
    "resnet_model.fc = nn.Linear(resnet_model.fc.in_features, num_classes)\n",
    "\n",
    "# Move the model to the GPU (if available)\n",
    "resnet_model = resnet_model.to(device)\n",
    "resnet_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the loss function (CrossEntropyLoss for classification tasks)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Define the optimizer (Adam or SGD)\n",
    "optimizer = optim.Adam(resnet_model.parameters(), lr=0.001)\n",
    "\n",
    "# Number of epochs\n",
    "num_epochs = 40"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resnet50 Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to train the model\n",
    "def train_model_resnet(model, train_loader, val_loader, criterion, optimizer, num_epochs, patience=10):\n",
    "    best_val_loss = float('inf')  # Initialize best validation loss as infinity\n",
    "    early_stop_counter = 0  # Count epochs with no improvement\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        start_time = time.time()\n",
    "\n",
    "        # --- TRAINING PHASE ---\n",
    "        model.train()  # Set the model to training mode\n",
    "        train_loss = 0.0\n",
    "        correct_train = 0\n",
    "        total_train = 0\n",
    "        \n",
    "        for images, labels in train_loader:\n",
    "            # Move images and labels to the GPU\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            # Forward pass: Get model predictions\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backward pass: Compute gradients and update weights\n",
    "            optimizer.zero_grad()  # Clear previous gradients\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Accumulate the training loss\n",
    "            train_loss += loss.item() * images.size(0)\n",
    "\n",
    "            # Track accuracy\n",
    "            _, predicted = outputs.max(1)\n",
    "            correct_train += predicted.eq(labels).sum().item()\n",
    "            total_train += labels.size(0)\n",
    "\n",
    "        avg_train_loss = train_loss / total_train\n",
    "        train_accuracy = 100.0 * correct_train / total_train\n",
    "\n",
    "        # --- VALIDATION PHASE ---\n",
    "        model.eval()  # Set the model to evaluation mode\n",
    "        val_loss = 0.0\n",
    "        correct_val = 0\n",
    "        total_val = 0\n",
    "\n",
    "        # We don't need gradients in the validation phase\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "                # Forward pass: Get model predictions\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                # Accumulate the validation loss\n",
    "                val_loss += loss.item() * images.size(0)\n",
    "\n",
    "                # Track validation accuracy\n",
    "                _, predicted = outputs.max(1)\n",
    "                correct_val += predicted.eq(labels).sum().item()\n",
    "                total_val += labels.size(0)\n",
    "\n",
    "        avg_val_loss = val_loss / total_val\n",
    "        val_accuracy = 100.0 * correct_val / total_val\n",
    "\n",
    "        # --- EARLY STOPPING CHECK ---\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            early_stop_counter = 0  # Reset counter if improvement\n",
    "            torch.save(model.state_dict(), 'Resnet50_New_TrainingTime.pt')  # Save the best model\n",
    "            print(f'Validation loss improved. Saving model at epoch {epoch+1}')\n",
    "        else:\n",
    "            early_stop_counter += 1  # Increment counter if no improvement\n",
    "\n",
    "        if early_stop_counter >= patience:\n",
    "            print(f'Early stopping at epoch {epoch+1}. Best validation loss: {best_val_loss:.4f}')\n",
    "            break\n",
    "\n",
    "        # Print the losses and accuracies for this epoch\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}]')\n",
    "        print(f'Train Loss: {avg_train_loss:.4f}, Train Accuracy: {train_accuracy:.2f}%')\n",
    "        print(f'Val Loss: {avg_val_loss:.4f}, Val Accuracy: {val_accuracy:.2f}%')\n",
    "        print(f'Time taken: {time.time() - start_time:.2f} seconds\\n')\n",
    "\n",
    "    print(\"Training Complete!\")\n",
    "    # Load the best model before returning\n",
    "    # model.load_state_dict(torch.load('Resnet50.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start training the model\n",
    "train_model_resnet(resnet_model, train_loader, val_loader, criterion, optimizer, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_on_test(model, test_loader, criterion):\n",
    "    # Load the best model saved during training\n",
    "    model.load_state_dict(torch.load('Resnet50_New_TrainingTime.pt'))\n",
    "    model.to(device)  # Ensure the model is on the same device\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    \n",
    "    test_loss = 0.0\n",
    "    correct_test = 0\n",
    "    total_test = 0\n",
    "\n",
    "    # We don't need gradients for evaluation\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Accumulate the test loss\n",
    "            test_loss += loss.item() * images.size(0)\n",
    "\n",
    "            # Track accuracy\n",
    "            _, predicted = outputs.max(1)\n",
    "            correct_test += predicted.eq(labels).sum().item()\n",
    "            total_test += labels.size(0)\n",
    "\n",
    "    avg_test_loss = test_loss / total_test\n",
    "    test_accuracy = 100.0 * correct_test / total_test\n",
    "    \n",
    "    print(f'Test Loss: {avg_test_loss:.4f}')\n",
    "    print(f'Test Accuracy: {test_accuracy:.2f}%')\n",
    "\n",
    "    return avg_test_loss, test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model_on_test(resnet_model, test_loader, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_model.load_state_dict(torch.load('Resnet50_New.pt'))\n",
    "resnet_model.eval()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sks",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
